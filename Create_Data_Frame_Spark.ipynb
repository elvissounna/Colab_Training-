{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create Data Frame Spark",
      "provenance": [],
      "authorship_tag": "ABX9TyMiEP1x9eMrfsjplnH4wWpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elvissounna/Colab_Training-/blob/main/Create_Data_Frame_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdQ9oe4kwJA"
      },
      "source": [
        "Setting Pyspark in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTJHNl3xl3On"
      },
      "source": [
        "#!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "#!pip install -q findspark pyspark\n",
        "#!wget -q https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip -q ngrok-stable-linux-amd64.zip\n",
        "#get_ipython().system_raw('./ngrok http 4041 &')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zRpagVim3Aq"
      },
      "source": [
        "import findspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, SQLContext,Row # ici tu peux importer regrouper les librairies que tu \n",
        "#veux importer en les s√©parant juste par un virgule\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#sc = SparkContext('local')\n",
        "spark = SparkSession(sc)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmQkbVWKnXCT",
        "outputId": "77459c26-3ce3-4f5f-8957-b9824ea35d9d"
      },
      "source": [
        "df = spark.createDataFrame ([\n",
        "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
        "\n",
        "])\n",
        "df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}